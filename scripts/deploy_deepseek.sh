#!/bin/bash

# DeepSeek AI æœ¬åœ°éƒ¨ç½²è„šæœ¬
# é€‚ç”¨äºŽ Linux/macOS

set -e

echo "ðŸš€ å¼€å§‹éƒ¨ç½² DeepSeek AI æœ¬åœ°æœåŠ¡..."

# æ£€æŸ¥ç³»ç»Ÿè¦æ±‚
echo "ðŸ“‹ æ£€æŸ¥ç³»ç»Ÿè¦æ±‚..."

# æ£€æŸ¥GPU
if command -v nvidia-smi &> /dev/null; then
    echo "âœ… æ£€æµ‹åˆ° NVIDIA GPU"
    nvidia-smi --query-gpu=name,memory.total --format=csv,noheader,nounits
else
    echo "âš ï¸  æœªæ£€æµ‹åˆ° NVIDIA GPUï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼ï¼ˆæ€§èƒ½è¾ƒæ…¢ï¼‰"
fi

# æ£€æŸ¥Docker
if command -v docker &> /dev/null; then
    echo "âœ… Docker å·²å®‰è£…"
else
    echo "âŒ Docker æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£… Docker"
    exit 1
fi

# æ£€æŸ¥Docker Compose
if command -v docker-compose &> /dev/null; then
    echo "âœ… Docker Compose å·²å®‰è£…"
else
    echo "âŒ Docker Compose æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£… Docker Compose"
    exit 1
fi

# åˆ›å»ºéƒ¨ç½²ç›®å½•
DEPLOY_DIR="./deepseek_deploy"
mkdir -p $DEPLOY_DIR
cd $DEPLOY_DIR

echo "ðŸ“ åˆ›å»ºéƒ¨ç½²ç›®å½•: $DEPLOY_DIR"

# åˆ›å»º docker-compose.yml
cat > docker-compose.yml << 'EOF'
version: '3.8'

services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # å¯é€‰ï¼šæ·»åŠ  Web UI
  ollama-webui:
    image: ghcr.io/ollama-webui/ollama-webui:main
    container_name: ollama-webui
    ports:
      - "3000:8080"
    environment:
      - OLLAMA_API_BASE_URL=http://ollama:11434/api
    depends_on:
      - ollama
    restart: unless-stopped

volumes:
  ollama_data:
EOF

echo "ðŸ“„ åˆ›å»º docker-compose.yml"

# åˆ›å»ºå¯åŠ¨è„šæœ¬
cat > start.sh << 'EOF'
#!/bin/bash

echo "ðŸš€ å¯åŠ¨ DeepSeek AI æœåŠ¡..."

# å¯åŠ¨æœåŠ¡
docker-compose up -d

echo "â³ ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 10

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
if curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "âœ… Ollama æœåŠ¡å¯åŠ¨æˆåŠŸ"
else
    echo "âŒ Ollama æœåŠ¡å¯åŠ¨å¤±è´¥"
    exit 1
fi

# ä¸‹è½½ DeepSeek æ¨¡åž‹
echo "ðŸ“¥ ä¸‹è½½ DeepSeek æ¨¡åž‹..."
docker exec ollama ollama pull deepseek-coder:6.7b

echo "ðŸŽ‰ DeepSeek AI éƒ¨ç½²å®Œæˆï¼"
echo ""
echo "ðŸ“Š æœåŠ¡ä¿¡æ¯ï¼š"
echo "  - Ollama API: http://localhost:11434"
echo "  - Web UI: http://localhost:3000"
echo "  - æ¨¡åž‹: deepseek-coder:6.7b"
echo ""
echo "ðŸ”§ å¸¸ç”¨å‘½ä»¤ï¼š"
echo "  - æŸ¥çœ‹æ—¥å¿—: docker-compose logs -f"
echo "  - åœæ­¢æœåŠ¡: docker-compose down"
echo "  - é‡å¯æœåŠ¡: docker-compose restart"
echo "  - æ›´æ–°æ¨¡åž‹: docker exec ollama ollama pull deepseek-coder:6.7b"
EOF

chmod +x start.sh

# åˆ›å»ºåœæ­¢è„šæœ¬
cat > stop.sh << 'EOF'
#!/bin/bash

echo "ðŸ›‘ åœæ­¢ DeepSeek AI æœåŠ¡..."
docker-compose down
echo "âœ… æœåŠ¡å·²åœæ­¢"
EOF

chmod +x stop.sh

# åˆ›å»ºæµ‹è¯•è„šæœ¬
cat > test.sh << 'EOF'
#!/bin/bash

echo "ðŸ§ª æµ‹è¯• DeepSeek AI æœåŠ¡..."

# æµ‹è¯• API è¿žæŽ¥
if curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "âœ… API è¿žæŽ¥æ­£å¸¸"
else
    echo "âŒ API è¿žæŽ¥å¤±è´¥"
    exit 1
fi

# æµ‹è¯•æ¨¡åž‹ç”Ÿæˆ
echo "ðŸ“ æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ..."
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-coder:6.7b",
    "prompt": "Hello, how are you?",
    "stream": false
  }' | jq -r '.response'

echo ""
echo "âœ… æµ‹è¯•å®Œæˆ"
EOF

chmod +x test.sh

# åˆ›å»º README
cat > README.md << 'EOF'
# DeepSeek AI æœ¬åœ°éƒ¨ç½²

## å¿«é€Ÿå¼€å§‹

1. å¯åŠ¨æœåŠ¡ï¼š
   ```bash
   ./start.sh
   ```

2. æµ‹è¯•æœåŠ¡ï¼š
   ```bash
   ./test.sh
   ```

3. åœæ­¢æœåŠ¡ï¼š
   ```bash
   ./stop.sh
   ```

## æœåŠ¡åœ°å€

- **Ollama API**: http://localhost:11434
- **Web UI**: http://localhost:3000

## å¯ç”¨æ¨¡åž‹

- `deepseek-coder:6.7b` - ä»£ç ç”Ÿæˆæ¨¡åž‹
- `deepseek-coder:33b` - æ›´å¤§æ¨¡åž‹ï¼ˆéœ€è¦æ›´å¤šæ˜¾å­˜ï¼‰

## API ä½¿ç”¨ç¤ºä¾‹

### æ–‡æœ¬ç”Ÿæˆ
```bash
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-coder:6.7b",
    "prompt": "Write a Python function to calculate fibonacci numbers",
    "stream": false
  }'
```

### èŠå¤©å¯¹è¯
```bash
curl -X POST http://localhost:11434/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-coder:6.7b",
    "messages": [
      {"role": "user", "content": "Hello, how are you?"}
    ],
    "stream": false
  }'
```

## æ•…éšœæŽ’é™¤

1. **GPU å†…å­˜ä¸è¶³**ï¼š
   - ä½¿ç”¨æ›´å°çš„æ¨¡åž‹ï¼š`deepseek-coder:6.7b`
   - å¢žåŠ ç³»ç»Ÿå†…å­˜
   - ä½¿ç”¨ CPU æ¨¡å¼ï¼ˆè¾ƒæ…¢ï¼‰

2. **æœåŠ¡å¯åŠ¨å¤±è´¥**ï¼š
   - æ£€æŸ¥ Docker æ˜¯å¦è¿è¡Œ
   - æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨
   - æŸ¥çœ‹æ—¥å¿—ï¼š`docker-compose logs -f`

3. **æ¨¡åž‹ä¸‹è½½å¤±è´¥**ï¼š
   - æ£€æŸ¥ç½‘ç»œè¿žæŽ¥
   - æ‰‹åŠ¨ä¸‹è½½ï¼š`docker exec ollama ollama pull deepseek-coder:6.7b`

## æ€§èƒ½ä¼˜åŒ–

1. **GPU ä¼˜åŒ–**ï¼š
   - ä½¿ç”¨ NVIDIA GPU
   - å®‰è£…æœ€æ–°é©±åŠ¨
   - é…ç½® CUDA çŽ¯å¢ƒ

2. **å†…å­˜ä¼˜åŒ–**ï¼š
   - å…³é—­ä¸å¿…è¦çš„æœåŠ¡
   - å¢žåŠ ç³»ç»Ÿå†…å­˜
   - ä½¿ç”¨æ›´å°çš„æ¨¡åž‹

3. **ç½‘ç»œä¼˜åŒ–**ï¼š
   - ä½¿ç”¨æœ¬åœ°ç½‘ç»œ
   - é…ç½®ä»£ç†ï¼ˆå¦‚éœ€è¦ï¼‰
EOF

echo "ðŸ“š åˆ›å»º README.md"

echo ""
echo "ðŸŽ‰ éƒ¨ç½²æ–‡ä»¶åˆ›å»ºå®Œæˆï¼"
echo ""
echo "ðŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œï¼š"
echo "1. è¿›å…¥éƒ¨ç½²ç›®å½•: cd $DEPLOY_DIR"
echo "2. å¯åŠ¨æœåŠ¡: ./start.sh"
echo "3. æµ‹è¯•æœåŠ¡: ./test.sh"
echo ""
echo "ï¿½ï¿½ è¯¦ç»†è¯´æ˜Žè¯·æŸ¥çœ‹ README.md" 